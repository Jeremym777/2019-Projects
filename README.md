# Projects


- [Workout 1](workout-1)
- [Workout 2](workout-2)
- [Workout 3](workout-3)
- [projects](projects)

These are the projects that I've created using R/Rstudio and Python. These various projects with descriptions include:
      
                                          -Storm Tracker (workout-1)-


• Analyzed and visualized various storm trajectories from 2010-2015 based on their locations and intensities.

• Reported various finding such as an increase number of storms over each year, and the duration of each one.

• Confirmed that the location of storms increased as well as their intensities.

                                      -Investment Modalities (workout-2)-


• Created and implemented an investment app within Shiny, that allows users to interacts with multiple
investment scenarios over a 50-year period.

• Analyzed the optimum expenditure needed that would yield the maximum return on investments.

• Established that U.S bonds would yield the maximum investment over a 50-year period.

                                  -Nobel Laureate Précis Compiler (workout-3)-


• Utilized web scraping techniques to extract and organize data of Nobel Laureates on Google Scholar.

• Analyzed and visualized frequently cited publications, commonly used words, and the most influential
publications within each Nobel Laureates field of study.

• Corroborated the inference that the Nobel Laureates shared similar publications that are influential to their
fields of study.

                             -San Francisco Food Safety Analysis (projects/project-1)-


• Utilized pandas, NumPy, seaborn and matplotlib to clean, visualize and manipulate data of various San Francisco businesses by removing irrelevant business scores. 

• Investigated that various businesses who had multiple inspections from 2016-2019 did not always improve their scores.

• Corroborated the inference that 4,299 business within the zip code of 94110 of San Francisco had a higher rate of success compared to any other area code by using a geospatial hexbin plot.



                                   -Spam/Ham Classification (projects/project-2)-
                               
• Employed train and test validation to create a binary classification model for spam and ham emails.

• Implemented a logistic regression model to distinguish between spam and ham emails based on selected features such as replies, forwards and words that appeared frequently within emails.

• Competed in a Kaggle competition and achieved a model accuracy of 97.2%.


                                                
                                          -Covid-19 (projects/Covid-19)-

• Utilized pandas, matplotlib and NumPy to perform geospatial and time series visualizations of records involving Covid-19.

• Created a Linear Regression model that predicted the number of confirmed cases, death cases, recovery cases, and mortality rate after a 30-day period out from May 10th.

• Reported that there will be approx. 2,843,315 more confirmed cases on June 9th.


